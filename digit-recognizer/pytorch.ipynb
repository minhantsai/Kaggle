{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_train = train[\"label\"]\n",
    "\n",
    "# Drop 'label' column\n",
    "X_train = train.drop(labels = [\"label\"],axis = 1) \n",
    "\n",
    "g = sns.countplot(Y_train)\n",
    "#Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       784\n",
       "unique        1\n",
       "top       False\n",
       "freq        784\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "#X_train = X_train / 255.0\n",
    "#test = test / 255.0\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5), (0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "pic should be 2/3 dimensional. Got 1 dimensions.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-b3e6be5abc39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \"\"\"\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_numpy_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pic should be 2/3 dimensional. Got {} dimensions.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: pic should be 2/3 dimensional. Got 1 dimensions."
     ]
    }
   ],
   "source": [
    "transform(X_train.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0, 188, 255,  94,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0, 191, 250, 253,  93,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0, 123, 248, 253, 167,  10,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  80, 247, 253, 208,  13,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,  29, 207, 253, 235,  77,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,  54, 209, 253, 253,  88,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  93, 254, 253, 238, 170,\n",
       "        17,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,  23, 210, 254, 253,\n",
       "       159,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  16, 209, 253,\n",
       "       254, 240,  81,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  27,\n",
       "       253, 253, 254,  13,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        20, 206, 254, 254, 198,   7,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0, 168, 253, 253, 196,   7,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,  20, 203, 253, 248,  76,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,  22, 188, 253, 245,  93,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0, 103, 253, 253, 191,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,  89, 240, 253, 195,  25,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  15, 220, 253, 253,  80,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  94, 253, 253,\n",
       "       253,  94,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  89,\n",
       "       251, 253, 250, 131,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0, 214, 218,  95,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val =train_test_split(X_train, Y_train, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "X_val = X_val.values.reshape(-1,28,28,1)\n",
    "test = test.values.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29400, 28, 28, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 22, 22, 32)        9248      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 15488)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                991296    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 1,010,762\n",
      "Trainable params: 1,010,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28,28,1), name = 'Input')\n",
    "\n",
    "conv1 = layers.Conv2D(32, 3,strides = 1,activation='relu',name = 'conv1')(inputs)\n",
    "conv2 = layers.Conv2D(32, 3,strides = 1,activation='relu',name = 'conv2')(conv1)\n",
    "conv3 = layers.Conv2D(32, 3,strides = 1,activation='relu',name = 'conv3')(conv2)\n",
    "\n",
    "flat = layers.Flatten()(conv3)\n",
    "dense = layers.Dense(64,activation='relu')(flat)\n",
    "outputs = layers.Dense(10,activation='softmax')(dense)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29400 samples, validate on 12600 samples\n",
      "Epoch 1/5\n",
      "29400/29400 [==============================] - 4s 149us/sample - loss: 0.1740 - accuracy: 0.9472 - val_loss: 0.0692 - val_accuracy: 0.9787\n",
      "Epoch 2/5\n",
      "29400/29400 [==============================] - 3s 104us/sample - loss: 0.0522 - accuracy: 0.9837 - val_loss: 0.0616 - val_accuracy: 0.9817\n",
      "Epoch 3/5\n",
      "29400/29400 [==============================] - 3s 106us/sample - loss: 0.0327 - accuracy: 0.9893 - val_loss: 0.0509 - val_accuracy: 0.9856\n",
      "Epoch 4/5\n",
      "29400/29400 [==============================] - 3s 103us/sample - loss: 0.0208 - accuracy: 0.9932 - val_loss: 0.0643 - val_accuracy: 0.9825\n",
      "Epoch 5/5\n",
      "29400/29400 [==============================] - 3s 100us/sample - loss: 0.0161 - accuracy: 0.9948 - val_loss: 0.0598 - val_accuracy: 0.9856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f167068a198>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train.values,validation_data=[X_val,Y_val.values],epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# output predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = list()\n",
    "id_list = np.arange(len(predict))+1\n",
    "\n",
    "\n",
    "for idx, arr in enumerate(predict):\n",
    "    ans.append(np.argmax(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "out['ImageId'] = id_list\n",
    "out['Label'] = ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_csv('sample.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
